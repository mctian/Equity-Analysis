{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "reload(Model)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# positive numbers, start should be lower than end\n",
    "# a rebalance index represents the month before the rebalancing takes place\n",
    "# so returns are calculated starting at rebalanceIndex + 1\n",
    "def rebalanceIndexes(startIndex, endIndex):\n",
    "    indexes = list(range(startIndex, endIndex, 3))\n",
    "    return (indexes)\n",
    "\n",
    "\n",
    "# get ln returns for an equally balanced portfolio of stocks\n",
    "def getReturns(portfolio, index, length):\n",
    "\treturns = 0\n",
    "\tprint(portfolio)\n",
    "\tprint(-1 * index + 1)\n",
    "\tprint(-1 * index + length)\n",
    "\tnancount = 0\n",
    "\tfor stock in portfolio:\n",
    "\t\tindReturn = Model.rateOfReturn(Model.retrieveData(stock, 'Last Price', -1 * index + 1, -1 * index + length, []))\n",
    "\t\tprint(stock + \": \" + str(indReturn))\n",
    "\t\tif (not math.isnan(indReturn)):\n",
    "\t\t\treturns += indReturn\n",
    "\t\telse:\n",
    "\t\t\tnancount += 1\n",
    "\tif len(portfolio) - nancount == 0:\n",
    "\t\ttotal = 0\n",
    "\telse:\n",
    "\t\ttotal = returns/(len(portfolio)-nancount)\n",
    "\tprint(\"Start Date: \" + str(Model.convertIndexToDate(-1 * index + 1)))\n",
    "\tprint(\"Total Return: \" +str(total))\n",
    "\treturn (total)\n",
    "\n",
    "\n",
    "# make a portfolio with predicted probabilities higher than a hardcoded threshold\n",
    "def makePortfolio(treeTuple):\n",
    "\tfeatureList = ['EPS Growth', 'Volatility 180 D', 'Trailing EPS', 'Price to Cash Flow', 'EPS', 'Volume', 'Return on Assets', 'Price to Book', 'Dividend Yield', 'Total Debt to Total Equity', 'Return on Invested Capital', 'Return on Common Equity']\n",
    "\taddedStocks, probabilities = Model.predict_probabilities(treeTuple[1], startIndex = -1 * treeTuple[0] - 11, endIndex = -1 * treeTuple[0], features = featureList, sector = \"Health Care\")\n",
    "\tprobabilityThreshold = 0.8\n",
    "\tstockTuples = zip(addedStocks, probabilities)\n",
    "\tstockTuples = list(filter(lambda x: x[1][1] > probabilityThreshold, stockTuples))\n",
    "\tif len(stockTuples) == 0:\n",
    "\t\tprint(\"No portfolio, probabilities lower than threshold of \" + str(probabilityThreshold))\n",
    "\t\treturn 0\n",
    "\tstocks, probabilities = zip(*stockTuples)\n",
    "\treturn(getReturns(stocks, treeTuple[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[array([-219, -216, -213, -210, -207, -204, -201, -198, -195, -192, -189,\n",
      "       -186, -183, -180, -177, -174, -171, -168, -165, -162, -159, -156,\n",
      "       -153, -150, -147, -144, -141, -138, -135, -132, -129, -126, -123,\n",
      "       -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,\n",
      "        -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,\n",
      "        -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,  -27,  -24,\n",
      "        -21]), array([-222, -219, -216, -213, -210, -207, -204, -201, -198, -195, -192,\n",
      "       -189, -186, -183, -180, -177, -174, -171, -168, -165, -162, -159,\n",
      "       -156, -153, -150, -147, -144, -141, -138, -135, -132, -129, -126,\n",
      "       -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,\n",
      "        -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,\n",
      "        -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,  -27,\n",
      "        -24]), array([-225, -222, -219, -216, -213, -210, -207, -204, -201, -198, -195,\n",
      "       -192, -189, -186, -183, -180, -177, -174, -171, -168, -165, -162,\n",
      "       -159, -156, -153, -150, -147, -144, -141, -138, -135, -132, -129,\n",
      "       -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,\n",
      "        -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,\n",
      "        -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,\n",
      "        -27]), array([-228, -225, -222, -219, -216, -213, -210, -207, -204, -201, -198,\n",
      "       -195, -192, -189, -186, -183, -180, -177, -174, -171, -168, -165,\n",
      "       -162, -159, -156, -153, -150, -147, -144, -141, -138, -135, -132,\n",
      "       -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,\n",
      "        -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,\n",
      "        -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,\n",
      "        -30]), array([-231, -228, -225, -222, -219, -216, -213, -210, -207, -204, -201,\n",
      "       -198, -195, -192, -189, -186, -183, -180, -177, -174, -171, -168,\n",
      "       -165, -162, -159, -156, -153, -150, -147, -144, -141, -138, -135,\n",
      "       -132, -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,\n",
      "        -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,\n",
      "        -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,\n",
      "        -33]), array([-234, -231, -228, -225, -222, -219, -216, -213, -210, -207, -204,\n",
      "       -201, -198, -195, -192, -189, -186, -183, -180, -177, -174, -171,\n",
      "       -168, -165, -162, -159, -156, -153, -150, -147, -144, -141, -138,\n",
      "       -135, -132, -129, -126, -123, -120, -117, -114, -111, -108, -105,\n",
      "       -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,\n",
      "        -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,\n",
      "        -36]), array([-237, -234, -231, -228, -225, -222, -219, -216, -213, -210, -207,\n",
      "       -204, -201, -198, -195, -192, -189, -186, -183, -180, -177, -174,\n",
      "       -171, -168, -165, -162, -159, -156, -153, -150, -147, -144, -141,\n",
      "       -138, -135, -132, -129, -126, -123, -120, -117, -114, -111, -108,\n",
      "       -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,\n",
      "        -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,\n",
      "        -39]), array([-240, -237, -234, -231, -228, -225, -222, -219, -216, -213, -210,\n",
      "       -207, -204, -201, -198, -195, -192, -189, -186, -183, -180, -177,\n",
      "       -174, -171, -168, -165, -162, -159, -156, -153, -150, -147, -144,\n",
      "       -141, -138, -135, -132, -129, -126, -123, -120, -117, -114, -111,\n",
      "       -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,\n",
      "        -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,\n",
      "        -42]), array([-243, -240, -237, -234, -231, -228, -225, -222, -219, -216, -213,\n",
      "       -210, -207, -204, -201, -198, -195, -192, -189, -186, -183, -180,\n",
      "       -177, -174, -171, -168, -165, -162, -159, -156, -153, -150, -147,\n",
      "       -144, -141, -138, -135, -132, -129, -126, -123, -120, -117, -114,\n",
      "       -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,\n",
      "        -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,\n",
      "        -45]), array([-246, -243, -240, -237, -234, -231, -228, -225, -222, -219, -216,\n",
      "       -213, -210, -207, -204, -201, -198, -195, -192, -189, -186, -183,\n",
      "       -180, -177, -174, -171, -168, -165, -162, -159, -156, -153, -150,\n",
      "       -147, -144, -141, -138, -135, -132, -129, -126, -123, -120, -117,\n",
      "       -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,\n",
      "        -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,\n",
      "        -48]), array([-249, -246, -243, -240, -237, -234, -231, -228, -225, -222, -219,\n",
      "       -216, -213, -210, -207, -204, -201, -198, -195, -192, -189, -186,\n",
      "       -183, -180, -177, -174, -171, -168, -165, -162, -159, -156, -153,\n",
      "       -150, -147, -144, -141, -138, -135, -132, -129, -126, -123, -120,\n",
      "       -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,\n",
      "        -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,\n",
      "        -51]), array([-252, -249, -246, -243, -240, -237, -234, -231, -228, -225, -222,\n",
      "       -219, -216, -213, -210, -207, -204, -201, -198, -195, -192, -189,\n",
      "       -186, -183, -180, -177, -174, -171, -168, -165, -162, -159, -156,\n",
      "       -153, -150, -147, -144, -141, -138, -135, -132, -129, -126, -123,\n",
      "       -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,\n",
      "        -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,\n",
      "        -54]), array([-255, -252, -249, -246, -243, -240, -237, -234, -231, -228, -225,\n",
      "       -222, -219, -216, -213, -210, -207, -204, -201, -198, -195, -192,\n",
      "       -189, -186, -183, -180, -177, -174, -171, -168, -165, -162, -159,\n",
      "       -156, -153, -150, -147, -144, -141, -138, -135, -132, -129, -126,\n",
      "       -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,\n",
      "        -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,\n",
      "        -57]), array([-258, -255, -252, -249, -246, -243, -240, -237, -234, -231, -228,\n",
      "       -225, -222, -219, -216, -213, -210, -207, -204, -201, -198, -195,\n",
      "       -192, -189, -186, -183, -180, -177, -174, -171, -168, -165, -162,\n",
      "       -159, -156, -153, -150, -147, -144, -141, -138, -135, -132, -129,\n",
      "       -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,\n",
      "        -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,\n",
      "        -60]), array([-261, -258, -255, -252, -249, -246, -243, -240, -237, -234, -231,\n",
      "       -228, -225, -222, -219, -216, -213, -210, -207, -204, -201, -198,\n",
      "       -195, -192, -189, -186, -183, -180, -177, -174, -171, -168, -165,\n",
      "       -162, -159, -156, -153, -150, -147, -144, -141, -138, -135, -132,\n",
      "       -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,\n",
      "        -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,\n",
      "        -63]), array([-264, -261, -258, -255, -252, -249, -246, -243, -240, -237, -234,\n",
      "       -231, -228, -225, -222, -219, -216, -213, -210, -207, -204, -201,\n",
      "       -198, -195, -192, -189, -186, -183, -180, -177, -174, -171, -168,\n",
      "       -165, -162, -159, -156, -153, -150, -147, -144, -141, -138, -135,\n",
      "       -132, -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,\n",
      "        -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,\n",
      "        -66]), array([-267, -264, -261, -258, -255, -252, -249, -246, -243, -240, -237,\n",
      "       -234, -231, -228, -225, -222, -219, -216, -213, -210, -207, -204,\n",
      "       -201, -198, -195, -192, -189, -186, -183, -180, -177, -174, -171,\n",
      "       -168, -165, -162, -159, -156, -153, -150, -147, -144, -141, -138,\n",
      "       -135, -132, -129, -126, -123, -120, -117, -114, -111, -108, -105,\n",
      "       -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,\n",
      "        -69]), array([-270, -267, -264, -261, -258, -255, -252, -249, -246, -243, -240,\n",
      "       -237, -234, -231, -228, -225, -222, -219, -216, -213, -210, -207,\n",
      "       -204, -201, -198, -195, -192, -189, -186, -183, -180, -177, -174,\n",
      "       -171, -168, -165, -162, -159, -156, -153, -150, -147, -144, -141,\n",
      "       -138, -135, -132, -129, -126, -123, -120, -117, -114, -111, -108,\n",
      "       -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,\n",
      "        -72])]\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for i in rebalanceIndexes(4,56):\n",
    "    maxLength = 200\n",
    "    targetLength = 3\n",
    "    featureLength = 12\n",
    "    indexes.append(np.arange(-1 * (targetLength + featureLength) - i + maxLength * -1, -1 * (targetLength + featureLength) - i, targetLength))\n",
    "print(len(indexes))\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multiprocess cpus: 8\n",
      "Finished data retrieval, starting model training. Time taken: 141.92156386375427 seconds.\n",
      "Finished fitting. Time taken: 21.719910860061646 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 150.30966687202454 seconds.\n",
      "Finished fitting. Time taken: 18.168582916259766 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 151.14323616027832 seconds.\n",
      "Finished fitting. Time taken: 11.82422399520874 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 125.5440309047699 seconds.\n",
      "Finished fitting. Time taken: 22.381747007369995 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 144.76649284362793 seconds.\n",
      "Finished fitting. Time taken: 13.604840993881226 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 123.99750399589539 seconds.\n",
      "Finished fitting. Time taken: 12.983163118362427 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 116.27580213546753 seconds.\n",
      "Finished fitting. Time taken: 10.999990940093994 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 205.15510082244873 seconds.\n",
      "Finished fitting. Time taken: 14.140430212020874 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 141.68551683425903 seconds.\n",
      "Finished fitting. Time taken: 15.100557088851929 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 121.25100684165955 seconds.\n",
      "Finished fitting. Time taken: 10.739354848861694 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 108.18309831619263 seconds.\n",
      "Finished fitting. Time taken: 10.824896097183228 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 108.04801917076111 seconds.\n",
      "Finished fitting. Time taken: 10.607080221176147 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 106.76797199249268 seconds.\n",
      "Finished fitting. Time taken: 10.782160758972168 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 110.45008420944214 seconds.\n",
      "Finished fitting. Time taken: 10.9378821849823 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 120.17974090576172 seconds.\n",
      "Finished fitting. Time taken: 11.116322040557861 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 114.09277415275574 seconds.\n",
      "Finished fitting. Time taken: 10.716581106185913 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 111.61056709289551 seconds.\n",
      "Finished fitting. Time taken: 10.721229076385498 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 114.36815524101257 seconds.\n",
      "Finished fitting. Time taken: 10.375672817230225 seconds.\n",
      "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "print(\"# of multiprocess cpus: \" + str(os.cpu_count()))\n",
    "sector = \"Health Care\"\n",
    "featureList = ['EPS Growth', 'Volatility 180 D', 'Trailing EPS', 'Price to Cash Flow', 'EPS', 'Volume', 'Return on Assets', 'Price to Book', 'Dividend Yield', 'Total Debt to Total Equity', 'Return on Invested Capital', 'Return on Common Equity']\n",
    "forestList = []\n",
    "for ind in indexes:\n",
    "\trandForest = Model.buildWithIndexesTripleClass(modelType = Model.randomForestClassifier, indexes = ind, target= 'Rate of Return', features = featureList, featureLength = 12,\\\n",
    "\t\t\t\t\t\t\t\t\ttargetLength = 3, sector = sector, percentileTarget = 90, percentileAvoid = 10, verbose = True)\n",
    "\tforestList.append(randForest)\n",
    "print(forestList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multiprocess cpus: 8\n",
      "('EDIT', 'ENTA', 'GTS')\n",
      "-3\n",
      "-1\n",
      "EDIT: 0.23478320199270186\n",
      "ENTA: 0.5368630680379205\n",
      "GTS: -0.21246885024834494\n",
      "Start Date: 2017-11-30\n",
      "Total Return: 0.18639247326075914\n",
      "('ABBV', 'ALGN', 'ASMB', 'EDIT', 'ENTA', 'JUNO', 'MDGL')\n",
      "Total Return: 0.29066121413827334\n",
      "-6\n",
      "-4\n",
      "ABBV: 0.18110346240714303\n",
      "ALGN: 0.3017001403317492\n",
      "ASMB: 0.08482652544427438\n",
      "EDIT: 0.1610967913107073\n",
      "ENTA: 0.14746213907382844\n",
      "JUNO: 0.08452464333515586\n",
      "MDGL: 1.073914797065055\n",
      "Start Date: 2017-08-31\n",
      "('ACOR', 'ALR', 'CCXI', 'CORT', 'CUTR', 'ENSG', 'ENTA', 'FGEN', 'JUNO', 'LMAT', 'PODD')\n",
      "Total Return: 0.23615714562430298\n",
      "-9\n",
      "-7\n",
      "ACOR: 0.45033686228533965\n",
      "ALR: 0.24983378523724786\n",
      "CCXI: 0.42337603467469465\n",
      "CORT: 0.09763846956391609\n",
      "CUTR: 0.1332572322389809\n",
      "ENSG: 0.19645765857449726\n",
      "ENTA: 0.23661621580412984\n",
      "FGEN: 0.26119364683308\n",
      "JUNO: 0.20200037888059041\n",
      "LMAT: 0.16576953061712807\n",
      "PODD: 0.18124878715772796\n",
      "Start Date: 2017-05-31\n",
      "('ALGN', 'BEAT', 'CORT', 'ENZ', 'GMED', 'LMAT', 'MASI', 'MDSO', 'MDXG', 'SUPN', 'VEEV', 'WOOF')\n",
      "Total Return: 0.2091931448561839\n",
      "-12\n",
      "-10\n",
      "ALGN: 0.2700598223408841\n",
      "BEAT: 0.25675691477479434\n",
      "CORT: 0.05938063697666607\n",
      "ENZ: 0.31067159067647987\n",
      "GMED: 0.08674165345461615\n",
      "LMAT: 0.29544320471114816\n",
      "MASI: 0.12839983343931927\n",
      "MDSO: 0.15705877095609289\n",
      "MDXG: 0.3925465491166076\n",
      "SUPN: 0.23782129647148764\n",
      "VEEV: 0.2048028898444687\n",
      "WOOF: 0.11063457551164202\n",
      "Start Date: 2017-02-28\n",
      "('BEAT', 'GMED', 'LHCG', 'MASI', 'PODD', 'RTRX', 'SUPN', 'ZTS')\n",
      "Total Return: 0.14995225253683936\n",
      "-15\n",
      "-13\n",
      "BEAT: 0.16981869937820226\n",
      "GMED: 0.1973042556560256\n",
      "LHCG: 0.17552246100085833\n",
      "MASI: 0.17333784013373066\n",
      "PODD: 0.21208711117648127\n",
      "RTRX: -0.042410945535980904\n",
      "SUPN: 0.2273111887427337\n",
      "ZTS: 0.08664740974266394\n",
      "Start Date: 2016-11-30\n",
      "('ADUS', 'CCXI', 'CUTR', 'MDGL', 'XNCR')\n",
      "MDGL: 0.35754111982658143\n",
      "-18\n",
      "-16\n",
      "ADUS: 0.053584246134106284\n",
      "CCXI: 0.17898265552844017\n",
      "CUTR: 0.18384944097200773\n",
      "XNCR: 0.007543647277422405\n",
      "Start Date: 2016-08-31\n",
      "Total Return: 0.1563002219477116\n",
      "('DXCM', 'REPH', 'VCRA', 'VNDA', 'XNCR')\n",
      "Total Return: 0.2317430056270756\n",
      "-21\n",
      "-19\n",
      "DXCM: 0.3577752842253412\n",
      "REPH: 0.16889046384051243\n",
      "VCRA: 0.24726583975490568\n",
      "VNDA: 0.09180754925312273\n",
      "XNCR: 0.2929758910614959\n",
      "Start Date: 2016-05-31\n",
      "('AMN', 'INGN', 'MDSO', 'SEM', 'SUPN')\n",
      "Total Return: 0.2881061259090294\n",
      "-24\n",
      "-22\n",
      "AMN: 0.22236942129208792\n",
      "INGN: 0.3573183881421498\n",
      "MDSO: 0.23478566309820392\n",
      "SEM: 0.3123995981576635\n",
      "SUPN: 0.3136575588550419\n",
      "Start Date: 2016-02-29\n",
      "No portfolio, probabilities lower than threshold of 0.8\n",
      "('CYTK',)\n",
      "Total Return: 0.21850854881006088\n",
      "-30\n",
      "-28\n",
      "CYTK: 0.21850854881006088\n",
      "Start Date: 2015-08-31\n",
      "('BEAT', 'SCMP')\n",
      "Total Return: 0.26576190088910745\n",
      "-33\n",
      "-31\n",
      "BEAT: 0.23693403434818627\n",
      "SCMP: 0.2945897674300286\n",
      "Start Date: 2015-05-29\n",
      "('ADUS', 'IONS', 'LMAT')\n",
      "-36\n",
      "-34\n",
      "ADUS: 0.20340667528102596\n",
      "IONS: -0.18958239206565253\n",
      "LMAT: 0.1730927503563331\n",
      "Start Date: 2015-02-27\n",
      "Total Return: 0.06230567785723551\n",
      "('ATHN', 'INSY', 'SCMP')\n",
      "-39\n",
      "-37\n",
      "ATHN: 0.17483409000296568\n",
      "INSY: 0.20999264837100284\n",
      "SCMP: 0.25074543822288087\n",
      "Start Date: 2014-11-28\n",
      "Total Return: 0.2118573921989498\n",
      "('CCRN', 'GHDX', 'SCMP', 'VASC')\n",
      "-42\n",
      "-40\n",
      "CCRN: 0.19208989800348553\n",
      "GHDX: 0.20109884311846704\n",
      "SCMP: 0.22401399965003432\n",
      "VASC: 0.21597506183559734\n",
      "Start Date: 2014-08-29\n",
      "Total Return: 0.20829445065189606\n",
      "No portfolio, probabilities lower than threshold of 0.8\n",
      "('PRSC',)\n",
      "-48\n",
      "-46\n",
      "PRSC: 0.42347913644327795\n",
      "Start Date: 2014-02-28\n",
      "Total Return: 0.42347913644327795\n",
      "('CCRN', 'SEM')\n",
      "-51\n",
      "-49\n",
      "CCRN: 0.34614853095174514\n",
      "SEM: 0.2208314115558303\n",
      "Start Date: 2013-11-29\n",
      "Total Return: 0.2834899712537877\n",
      "('ADUS', 'AMRI', 'KND', 'LMAT', 'NUVA', 'STAA')\n",
      "-54\n",
      "-52\n",
      "ADUS: 0.19925326078117767\n",
      "AMRI: 0.04556808790951106\n",
      "KND: -0.05739853870603229\n",
      "LMAT: 0.14712730867216162\n",
      "NUVA: 0.3009860380781437\n",
      "STAA: 0.20115121718068174\n",
      "Start Date: 2013-08-30\n",
      "Total Return: 0.13944789565260726\n",
      "[0.18639247326075914, 0.29066121413827334, 0.23615714562430298, 0.2091931448561839, 0.14995225253683936, 0.1563002219477116, 0.2317430056270756, 0.2881061259090294, 0, 0.21850854881006088, 0.26576190088910745, 0.06230567785723551, 0.2118573921989498, 0.20829445065189606, 0, 0.42347913644327795, 0.2834899712537877, 0.13944789565260726]\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(os.cpu_count())\n",
    "print(\"# of multiprocess cpus: \" + str(os.cpu_count()))\n",
    "returnsList = pool.map(makePortfolio, zip(rebalanceIndexes(4,56), forestList))\n",
    "print(returnsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
