{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "reload(Model)\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "# positive numbers, start should be lower than end\n",
    "# a rebalance index represents the month before the rebalancing takes place\n",
    "# so returns are calculated starting at rebalanceIndex + 1\n",
    "def rebalanceIndexes(startIndex, endIndex):\n",
    "    indexes = list(range(startIndex, endIndex, 3))\n",
    "    return (indexes)\n",
    "\n",
    "\n",
    "# get ln returns for an equally balanced portfolio of stocks\n",
    "def getReturns(portfolio, index, length):\n",
    "\treturns = 0\n",
    "\tprint(portfolio)\n",
    "\tprint(-1 * index + 1)\n",
    "\tprint(-1 * index + length)\n",
    "\tnancount = 0\n",
    "\tfor stock in portfolio:\n",
    "\t\tindReturn = Model.rateOfReturn(Model.retrieveData(stock, 'Last Price', -1 * index + 1, -1 * index + length, []))\n",
    "\t\tprint(stock + \": \" + str(indReturn))\n",
    "\t\tif (not math.isnan(indReturn)):\n",
    "\t\t\treturns += indReturn\n",
    "\t\telse:\n",
    "\t\t\tnancount += 1\n",
    "\tif len(portfolio) - nancount == 0:\n",
    "\t\ttotal = 0\n",
    "\telse:\n",
    "\t\ttotal = returns/(len(portfolio)-nancount)\n",
    "\tprint(\"Start Date: \" + str(Model.convertIndexToDate(-1 * index + 1)))\n",
    "\tprint(\"Total Return: \" +str(total))\n",
    "\treturn (total)\n",
    "\n",
    "\n",
    "# make a portfolio with predicted probabilities higher than a hardcoded threshold\n",
    "def makePortfolio(treeTuple):\n",
    "\tfeatureList = ['EPS Growth', 'Volatility 180 D', 'Trailing EPS', 'Price to Cash Flow', 'EPS', 'Volume', 'Return on Assets', 'Price to Book', 'Dividend Yield', 'Total Debt to Total Equity', 'Return on Invested Capital', 'Return on Common Equity']\n",
    "\taddedStocks, probabilities = Model.predict_probabilities(treeTuple[1], startIndex = -1 * treeTuple[0] - 11, endIndex = -1 * treeTuple[0], features = featureList, sector = \"Consumer Discretionary\")\n",
    "\tprobabilityThreshold = 0.8\n",
    "\tstockTuples = zip(addedStocks, probabilities)\n",
    "\tstockTuples = list(filter(lambda x: x[1][1] > probabilityThreshold, stockTuples))\n",
    "\tif len(stockTuples) == 0:\n",
    "\t\tprint(\"No portfolio, probabilities lower than threshold of \" + str(probabilityThreshold))\n",
    "\t\treturn 0\n",
    "\tstocks, probabilities = zip(*stockTuples)\n",
    "\treturn(getReturns(stocks, treeTuple[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[array([-219, -216, -213, -210, -207, -204, -201, -198, -195, -192, -189,\n",
      "       -186, -183, -180, -177, -174, -171, -168, -165, -162, -159, -156,\n",
      "       -153, -150, -147, -144, -141, -138, -135, -132, -129, -126, -123,\n",
      "       -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,\n",
      "        -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,\n",
      "        -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,  -27,  -24,\n",
      "        -21]), array([-222, -219, -216, -213, -210, -207, -204, -201, -198, -195, -192,\n",
      "       -189, -186, -183, -180, -177, -174, -171, -168, -165, -162, -159,\n",
      "       -156, -153, -150, -147, -144, -141, -138, -135, -132, -129, -126,\n",
      "       -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,\n",
      "        -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,\n",
      "        -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,  -27,\n",
      "        -24]), array([-225, -222, -219, -216, -213, -210, -207, -204, -201, -198, -195,\n",
      "       -192, -189, -186, -183, -180, -177, -174, -171, -168, -165, -162,\n",
      "       -159, -156, -153, -150, -147, -144, -141, -138, -135, -132, -129,\n",
      "       -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,\n",
      "        -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,\n",
      "        -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,  -30,\n",
      "        -27]), array([-228, -225, -222, -219, -216, -213, -210, -207, -204, -201, -198,\n",
      "       -195, -192, -189, -186, -183, -180, -177, -174, -171, -168, -165,\n",
      "       -162, -159, -156, -153, -150, -147, -144, -141, -138, -135, -132,\n",
      "       -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,\n",
      "        -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,\n",
      "        -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,  -33,\n",
      "        -30]), array([-231, -228, -225, -222, -219, -216, -213, -210, -207, -204, -201,\n",
      "       -198, -195, -192, -189, -186, -183, -180, -177, -174, -171, -168,\n",
      "       -165, -162, -159, -156, -153, -150, -147, -144, -141, -138, -135,\n",
      "       -132, -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,\n",
      "        -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,\n",
      "        -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,  -36,\n",
      "        -33]), array([-234, -231, -228, -225, -222, -219, -216, -213, -210, -207, -204,\n",
      "       -201, -198, -195, -192, -189, -186, -183, -180, -177, -174, -171,\n",
      "       -168, -165, -162, -159, -156, -153, -150, -147, -144, -141, -138,\n",
      "       -135, -132, -129, -126, -123, -120, -117, -114, -111, -108, -105,\n",
      "       -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,\n",
      "        -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,  -39,\n",
      "        -36]), array([-237, -234, -231, -228, -225, -222, -219, -216, -213, -210, -207,\n",
      "       -204, -201, -198, -195, -192, -189, -186, -183, -180, -177, -174,\n",
      "       -171, -168, -165, -162, -159, -156, -153, -150, -147, -144, -141,\n",
      "       -138, -135, -132, -129, -126, -123, -120, -117, -114, -111, -108,\n",
      "       -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,\n",
      "        -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,  -42,\n",
      "        -39]), array([-240, -237, -234, -231, -228, -225, -222, -219, -216, -213, -210,\n",
      "       -207, -204, -201, -198, -195, -192, -189, -186, -183, -180, -177,\n",
      "       -174, -171, -168, -165, -162, -159, -156, -153, -150, -147, -144,\n",
      "       -141, -138, -135, -132, -129, -126, -123, -120, -117, -114, -111,\n",
      "       -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,\n",
      "        -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,  -45,\n",
      "        -42]), array([-243, -240, -237, -234, -231, -228, -225, -222, -219, -216, -213,\n",
      "       -210, -207, -204, -201, -198, -195, -192, -189, -186, -183, -180,\n",
      "       -177, -174, -171, -168, -165, -162, -159, -156, -153, -150, -147,\n",
      "       -144, -141, -138, -135, -132, -129, -126, -123, -120, -117, -114,\n",
      "       -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,\n",
      "        -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,  -48,\n",
      "        -45]), array([-246, -243, -240, -237, -234, -231, -228, -225, -222, -219, -216,\n",
      "       -213, -210, -207, -204, -201, -198, -195, -192, -189, -186, -183,\n",
      "       -180, -177, -174, -171, -168, -165, -162, -159, -156, -153, -150,\n",
      "       -147, -144, -141, -138, -135, -132, -129, -126, -123, -120, -117,\n",
      "       -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,\n",
      "        -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,  -51,\n",
      "        -48]), array([-249, -246, -243, -240, -237, -234, -231, -228, -225, -222, -219,\n",
      "       -216, -213, -210, -207, -204, -201, -198, -195, -192, -189, -186,\n",
      "       -183, -180, -177, -174, -171, -168, -165, -162, -159, -156, -153,\n",
      "       -150, -147, -144, -141, -138, -135, -132, -129, -126, -123, -120,\n",
      "       -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,  -87,\n",
      "        -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,  -54,\n",
      "        -51]), array([-252, -249, -246, -243, -240, -237, -234, -231, -228, -225, -222,\n",
      "       -219, -216, -213, -210, -207, -204, -201, -198, -195, -192, -189,\n",
      "       -186, -183, -180, -177, -174, -171, -168, -165, -162, -159, -156,\n",
      "       -153, -150, -147, -144, -141, -138, -135, -132, -129, -126, -123,\n",
      "       -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,  -90,\n",
      "        -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,  -57,\n",
      "        -54]), array([-255, -252, -249, -246, -243, -240, -237, -234, -231, -228, -225,\n",
      "       -222, -219, -216, -213, -210, -207, -204, -201, -198, -195, -192,\n",
      "       -189, -186, -183, -180, -177, -174, -171, -168, -165, -162, -159,\n",
      "       -156, -153, -150, -147, -144, -141, -138, -135, -132, -129, -126,\n",
      "       -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,  -93,\n",
      "        -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,  -60,\n",
      "        -57]), array([-258, -255, -252, -249, -246, -243, -240, -237, -234, -231, -228,\n",
      "       -225, -222, -219, -216, -213, -210, -207, -204, -201, -198, -195,\n",
      "       -192, -189, -186, -183, -180, -177, -174, -171, -168, -165, -162,\n",
      "       -159, -156, -153, -150, -147, -144, -141, -138, -135, -132, -129,\n",
      "       -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,  -96,\n",
      "        -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,  -63,\n",
      "        -60]), array([-261, -258, -255, -252, -249, -246, -243, -240, -237, -234, -231,\n",
      "       -228, -225, -222, -219, -216, -213, -210, -207, -204, -201, -198,\n",
      "       -195, -192, -189, -186, -183, -180, -177, -174, -171, -168, -165,\n",
      "       -162, -159, -156, -153, -150, -147, -144, -141, -138, -135, -132,\n",
      "       -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,  -99,\n",
      "        -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,  -66,\n",
      "        -63]), array([-264, -261, -258, -255, -252, -249, -246, -243, -240, -237, -234,\n",
      "       -231, -228, -225, -222, -219, -216, -213, -210, -207, -204, -201,\n",
      "       -198, -195, -192, -189, -186, -183, -180, -177, -174, -171, -168,\n",
      "       -165, -162, -159, -156, -153, -150, -147, -144, -141, -138, -135,\n",
      "       -132, -129, -126, -123, -120, -117, -114, -111, -108, -105, -102,\n",
      "        -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,  -69,\n",
      "        -66]), array([-267, -264, -261, -258, -255, -252, -249, -246, -243, -240, -237,\n",
      "       -234, -231, -228, -225, -222, -219, -216, -213, -210, -207, -204,\n",
      "       -201, -198, -195, -192, -189, -186, -183, -180, -177, -174, -171,\n",
      "       -168, -165, -162, -159, -156, -153, -150, -147, -144, -141, -138,\n",
      "       -135, -132, -129, -126, -123, -120, -117, -114, -111, -108, -105,\n",
      "       -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,  -72,\n",
      "        -69]), array([-270, -267, -264, -261, -258, -255, -252, -249, -246, -243, -240,\n",
      "       -237, -234, -231, -228, -225, -222, -219, -216, -213, -210, -207,\n",
      "       -204, -201, -198, -195, -192, -189, -186, -183, -180, -177, -174,\n",
      "       -171, -168, -165, -162, -159, -156, -153, -150, -147, -144, -141,\n",
      "       -138, -135, -132, -129, -126, -123, -120, -117, -114, -111, -108,\n",
      "       -105, -102,  -99,  -96,  -93,  -90,  -87,  -84,  -81,  -78,  -75,\n",
      "        -72])]\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for i in rebalanceIndexes(4,56):\n",
    "    maxLength = 200\n",
    "    targetLength = 3\n",
    "    featureLength = 12\n",
    "    indexes.append(np.arange(-1 * (targetLength + featureLength) - i + maxLength * -1, -1 * (targetLength + featureLength) - i, targetLength))\n",
    "print(len(indexes))\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multiprocess cpus: 8\n",
      "Finished data retrieval, starting model training. Time taken: 125.98543810844421 seconds.\n",
      "Finished fitting. Time taken: 23.425883054733276 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 117.17932224273682 seconds.\n",
      "Finished fitting. Time taken: 23.369773864746094 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 147.02545404434204 seconds.\n",
      "Finished fitting. Time taken: 23.65790891647339 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 152.43960690498352 seconds.\n",
      "Finished fitting. Time taken: 26.623984813690186 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 118.300705909729 seconds.\n",
      "Finished fitting. Time taken: 23.866416215896606 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 118.92869710922241 seconds.\n",
      "Finished fitting. Time taken: 22.31186008453369 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 444.9844319820404 seconds.\n",
      "Finished fitting. Time taken: 35.05056309700012 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 209.69674706459045 seconds.\n",
      "Finished fitting. Time taken: 23.40845489501953 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 135.00097823143005 seconds.\n",
      "Finished fitting. Time taken: 29.117271184921265 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 170.2944619655609 seconds.\n",
      "Finished fitting. Time taken: 26.971675872802734 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 159.5415050983429 seconds.\n",
      "Finished fitting. Time taken: 30.479235649108887 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 176.87336921691895 seconds.\n",
      "Finished fitting. Time taken: 32.09159302711487 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 146.26361203193665 seconds.\n",
      "Finished fitting. Time taken: 33.70697808265686 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 177.5270619392395 seconds.\n",
      "Finished fitting. Time taken: 22.216032028198242 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 149.78339886665344 seconds.\n",
      "Finished fitting. Time taken: 27.27816104888916 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 175.813321352005 seconds.\n",
      "Finished fitting. Time taken: 24.280300855636597 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 145.45392298698425 seconds.\n",
      "Finished fitting. Time taken: 20.586944103240967 seconds.\n",
      "Finished data retrieval, starting model training. Time taken: 134.021244764328 seconds.\n",
      "Finished fitting. Time taken: 23.604865789413452 seconds.\n",
      "[RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False), RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "print(\"# of multiprocess cpus: \" + str(os.cpu_count()))\n",
    "sector = \"Consumer Discretionary\"\n",
    "featureList = ['EPS Growth', 'Volatility 180 D', 'Trailing EPS', 'Price to Cash Flow', 'EPS', 'Volume', 'Return on Assets', 'Price to Book', 'Dividend Yield', 'Total Debt to Total Equity', 'Return on Invested Capital', 'Return on Common Equity']\n",
    "forestList = []\n",
    "for ind in indexes:\n",
    "\trandForest = Model.buildWithIndexesTripleClass(modelType = Model.randomForestClassifier, indexes = ind, target= 'Rate of Return', features = featureList, featureLength = 12,\\\n",
    "\t\t\t\t\t\t\t\t\ttargetLength = 3, sector = sector, percentileTarget = 90, percentileAvoid = 10, verbose = True)\n",
    "\tforestList.append(randForest)\n",
    "print(forestList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of multiprocess cpus: 8\n",
      "('CTRN', 'ZAGG')\n",
      "Total Return: -0.14756756020368833\n",
      "-3\n",
      "-1\n",
      "CTRN: -0.09256095734127534\n",
      "ZAGG: -0.20257416306610132\n",
      "Start Date: 2017-11-30\n",
      "('CPLA', 'CTRN', 'DAN', 'ERI', 'EXPR', 'FIVE', 'OSTK', 'RH', 'SHAK', 'TLYS', 'TPH', 'ZAGG')\n",
      "ERI: 0.11099677597202451\n",
      "-6\n",
      "-4\n",
      "CPLA: 0.19008643219168064\n",
      "CTRN: 0.1825053972209827\n",
      "DAN: 0.23643250920518266\n",
      "EXPR: 0.06090161734011157\n",
      "FIVE: 0.14966602995367229\n",
      "OSTK: 0.7376979775453192\n",
      "RH: 0.6532508812672555\n",
      "SHAK: 0.20512975002250577\n",
      "TLYS: 0.07857443263262054\n",
      "TPH: 0.3282528580276769\n",
      "ZAGG: 0.21677410302873001\n",
      "Start Date: 2017-08-31\n",
      "Total Return: 0.26252239703398017\n",
      "('CROX', 'ERI', 'SNI', 'SNOW', 'W', 'ZAGG')\n",
      "-9\n",
      "-7\n",
      "CROX: 0.15058860167634558\n",
      "ERI: -0.01701134582653685\n",
      "SNI: 0.27762716047329583\n",
      "SNOW: 0.16129240795833066\n",
      "W: 0.19298727117428527\n",
      "ZAGG: 0.011904902506318038\n",
      "Start Date: 2017-05-31\n",
      "Total Return: 0.12956483299367308\n",
      "('BPI', 'ILG', 'IRBT', 'LOPE', 'OLLI', 'RH', 'W')\n",
      "Total Return: 0.270624932731843\n",
      "-12\n",
      "-10\n",
      "BPI: 0.2682009368799583\n",
      "ILG: 0.24452353147572525\n",
      "IRBT: 0.3343175493445738\n",
      "LOPE: 0.20253512535367424\n",
      "OLLI: 0.20023562910767057\n",
      "RH: 0.4548182825204874\n",
      "W: 0.18974347444081152\n",
      "Start Date: 2017-02-28\n",
      "('CPS', 'LRN', 'NCLH', 'SNOW', 'TSQ', 'UTI')\n",
      "Total Return: 0.21827430162227612\n",
      "-15\n",
      "-13\n",
      "CPS: 0.09938381534646545\n",
      "LRN: 0.30574011103833376\n",
      "NCLH: 0.16602946469783264\n",
      "SNOW: 0.2908967709722554\n",
      "TSQ: 0.2016074636805376\n",
      "UTI: 0.24598818399823197\n",
      "Start Date: 2016-11-30\n",
      "('BGFV', 'CPLA', 'IRBT', 'ZUMZ')\n",
      "IRBT: 0.24055259581248878\n",
      "-18\n",
      "-16\n",
      "BGFV: 0.21431169944638118\n",
      "CPLA: 0.21564777516130373\n",
      "ZUMZ: 0.28693328918953975\n",
      "Start Date: 2016-08-31\n",
      "Total Return: 0.23936133990242836\n",
      "('CACQ', 'TLYS', 'TPH', 'TPX')\n",
      "Total Return: 0.1476700453176658\n",
      "-21\n",
      "-19\n",
      "CACQ: 0.2224832673681345\n",
      "TLYS: -0.03624210277343409\n",
      "TPH: 0.14281492512550198\n",
      "TPX: 0.26162409155046085\n",
      "Start Date: 2016-05-31\n",
      "('APEI', 'BPI', 'IBP', 'LRN', 'ULTA')\n",
      "Total Return: 0.2898595928082107\n",
      "-24\n",
      "-22\n",
      "APEI: 0.40611298632972526\n",
      "BPI: 0.4101932493041103\n",
      "IBP: 0.17378025964404475\n",
      "LRN: 0.22742446703552455\n",
      "ULTA: 0.23178700172764888\n",
      "Start Date: 2016-02-29\n",
      "('BGFV', 'VRA', 'ZUMZ')\n",
      "Total Return: 0.20976959668114015\n",
      "-27\n",
      "-25\n",
      "BGFV: 0.23098025877500916\n",
      "VRA: 0.21589653215284654\n",
      "ZUMZ: 0.18243199911556474\n",
      "Start Date: 2015-11-30\n",
      "('CORE', 'FRAN', 'TTS')\n",
      "Total Return: 0.24487118504316255\n",
      "-30\n",
      "-28\n",
      "CORE: 0.3018467907074105\n",
      "FRAN: 0.2344670976434644\n",
      "TTS: 0.19829966677861277\n",
      "Start Date: 2015-08-31\n",
      "('TAST',)\n",
      "Total Return: 0.09512870806804985\n",
      "-33\n",
      "-31\n",
      "TAST: 0.09512870806804985\n",
      "Start Date: 2015-05-29\n",
      "No portfolio, probabilities lower than threshold of 0.8\n",
      "('LULU', 'TLYS')\n",
      "Total Return: 0.4637746335371198\n",
      "-39\n",
      "-37\n",
      "LULU: 0.3181329794247625\n",
      "TLYS: 0.6094162876494771\n",
      "Start Date: 2014-11-28\n",
      "('BWLD', 'GNC', 'KIRK', 'OSTK')\n",
      "GNC: 0.0911092494229071\n",
      "-42\n",
      "-40\n",
      "BWLD: -0.016519885799685774\n",
      "KIRK: -0.0016839745770091952\n",
      "OSTK: 0.26882975747257154\n",
      "Start Date: 2014-08-29\n",
      "Total Return: 0.08543378662969592\n",
      "('BBW', 'CMG', 'FRGI', 'GRBK', 'SFLY')\n",
      "Total Return: 0.24164723791430368\n",
      "-45\n",
      "-43\n",
      "BBW: 0.2149584861069771\n",
      "CMG: 0.20638878876737632\n",
      "FRGI: 0.1194647044883328\n",
      "GRBK: 0.4860754161374996\n",
      "SFLY: 0.18134879407133253\n",
      "Start Date: 2014-05-30\n",
      "('BLMN', 'HBI')\n",
      "Total Return: 0.22558479215435479\n",
      "-48\n",
      "-46\n",
      "BLMN: 0.26953856514602936\n",
      "HBI: 0.1816310191626802\n",
      "Start Date: 2014-02-28\n",
      "('BLMN', 'CALI')\n",
      "Total Return: 0.10871382308956701\n",
      "-51\n",
      "-49\n",
      "BLMN: -0.06593476512813057\n",
      "CALI: 0.2833624113072646\n",
      "Start Date: 2013-11-29\n",
      "('LOPE', 'TOWR')\n",
      "-54\n",
      "-52\n",
      "LOPE: 0.31462670769523315\n",
      "TOWR: 0.035495333014529784\n",
      "Start Date: 2013-08-30\n",
      "Total Return: 0.17506102035488147\n",
      "[-0.14756756020368833, 0.26252239703398017, 0.12956483299367308, 0.270624932731843, 0.21827430162227612, 0.23936133990242836, 0.1476700453176658, 0.2898595928082107, 0.20976959668114015, 0.24487118504316255, 0.09512870806804985, 0, 0.4637746335371198, 0.08543378662969592, 0.24164723791430368, 0.22558479215435479, 0.10871382308956701, 0.17506102035488147]\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(os.cpu_count())\n",
    "print(\"# of multiprocess cpus: \" + str(os.cpu_count()))\n",
    "returnsList = pool.map(makePortfolio, zip(rebalanceIndexes(4,56), forestList))\n",
    "print(returnsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
